<div align="center">

# ğŸ“ˆ llmonitor

**Open-source monitoring & observability for AI apps and agents**

[website](https://llmonitor.com) - [docs](https://llmonitor.com/docs) - [pricing](https://llmonitor.com/docs) - [self host](https://llmonitor.com/docs/self-host)

[![npm version](https://badge.fury.io/js/llmonitor.svg)](https://badge.fury.io/js/llmonitor) - ![Discord](https://img.shields.io/badge/Discord-Join%20Chat-violet?labelColor=purple&style=flat&logo=discord&logoColor=white)

</div>

## Features

LLMonitor helps AI devs monitor their apps in production, with features such as:

- ğŸ’µ Cost, token & latency analytics
- ğŸ‘ª Track users
- ğŸ› Debug agents with traces
- ğŸ” Inspect full requests
- ğŸ¤– Use with any model, not just OpenAI
- ğŸ“¦ Integrate in 2 minutes
- ğŸ§‘â€ğŸ’» Simple to self-host (deploy to Vercel & Supabase)

## Demo

https://github.com/LLMonitor/llmonitor/assets/5092466/a2b4ba9b-4afb-46e3-9b6b-faf7ddb4a931


## âš™ï¸ Integration

Modules available for:

- [JavaScript](https://github.com/llmonitor/llmonitor-js)
- Python (coming soon)

LLMonitor natively supports:

- [LangChain](https://llmonitor.com/docs/langchain) (JS & Python)
- [OpenAI module](https://llmonitor.com/docs/js/openai)
- [LiteLLM](https://docs.litellm.ai/docs/observability/llmonitor_integration)

Additionally you can use it with any framework by wrapping the relevant methods.

## ğŸ“š Documentation

Full documentation is available [on the website](https://llmonitor.com/docs/intro).

## â˜ï¸ Hosted version

We offer [a hosted version](https://llmonitor.com) with a free plan of up to 1k requests / days.

With the hosted version:
- ğŸ‘· don't worry about devops or managing updates
- ğŸ™‹ get priority 1:1 support with our team
- ğŸ‡ªğŸ‡º your data is stored safely in Europe

## ğŸ™‹ Support

Chat with us on [Discord](https://discord.gg/8PafSG58kK) or email one of the founders: [vince [at] llmonitor.com](mailto:vince@llmonitor.com).

## License

This project is licensed under the Apache 2.0 License.
