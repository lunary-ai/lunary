<div align="center">

# ğŸ“ˆ llmonitor

**Open-source monitoring & observability for AI apps and agents**

[website](https://llmonitor.com) - [docs](https://llmonitor.com/docs) - [demo](https://app.llmonitor.com/demo)

[![npm version](https://badge.fury.io/js/llmonitor.svg)](https://badge.fury.io/js/llmonitor) - ![Discord](https://img.shields.io/badge/Discord-Join%20Chat-violet?labelColor=purple&style=flat&logo=discord&logoColor=white)

</div>

- ğŸ§‘â€ğŸ’» Simple to self-host (deploy to Vercel & Supabase)
- ğŸ’µ Cost, token & latency analytics
- ğŸ‘ª Track users
- ğŸ› Debug agents with traces
- ğŸ” Inspect full requests
- ğŸ¤– Use with any model, not just OpenAI
- ğŸ“¦ Integrate in 2 minutes

<video controls width="900"><source src="https://llmonitor.com/videos/demo-annotated.mp4"></video>

## âš™ï¸ Integration

Modules available for:

- [JavaScript](https://github.com/llmonitor/llmonitor-js)
- Python (coming soon)

LLMonitor natively supports:

- LangChain (JS & Python)
- OpenAI module
- LiteLLM

Additionally you can use it with any framework by wrapping the relevant methods.

## ğŸ“š Documentation

Full documentation is available [on the website](https://llmonitor.com/docs/intro).

## ğŸ™‹ Support

Chat with us on [Discord](https://discord.gg/8PafSG58kK) or email one of the founders at vince@llmonitor.com.

## License

This project is licensed under the Apache 2.0 License.
