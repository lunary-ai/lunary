<div align="center">

<img src="https://llmonitor.com/logo.png" style='border-radius: 12px;' width="50"/>

# ğŸ“ˆ llmonitor

**Monitoring for AI apps and agent**

[website](https://llmonitor.com) - [docs](https://llmonitor.com/docs) - [demo](https://app.llmonitor.com/demo) - [![npm version](https://badge.fury.io/js/llmonitor.svg)](https://badge.fury.io/js/llmonitor) = ![Discord](https://img.shields.io/badge/Discord-Join%20Chat-violet?labelColor=purple&style=flat&logo=discord&logoColor=white)

---

</div>

- ğŸ§‘â€ğŸ’» Simple to self-host (deploy to Vercel & Supabase)
- ğŸ’µ Cost, token & latency analytics
- ğŸ‘ª Track users
- ğŸ› Debug agents with traces
- ğŸ” Inspect full requests
- ğŸ¤– Use with any model, not just OpenAI
- ğŸ“¦ Integrate in 2 minutes

Currently, a [JS client](https://github.com/llmonitor/llmonitor-js) is available with Python in the works.

## ğŸ“š Documentation

Full documentation is available [on the website](https://llmonitor.com/docs/intro).

## ğŸ™‹ Support

Chat with us on [Discord](https://discord.gg/8PafSG58kK) or email one of the founders at vince@llmonitor.com.

## License

This project is licensed under the Apache 2.0 License.
